= 人脸识别

== 概述

== 爬虫准备样本数据

* beautifulsoup4
* urllib3

== 简单的图片爬虫

```
#'https://class.imooc.com/?c=ios&mc_marking=286b51b2a8e40915ea9023c821882e74&mc_channel=L5
# 爬虫 1 理解爬虫原理 2 实现一个的图片爬虫
# 1 http 2 html 3 正则 过滤条件 4 其它
# 1 url 2 html src 3 img 4 img url
import urllib
import urllib3
import os
from bs4 import BeautifulSoup
# load url
html = urllib.request.urlopen('https://www.baidu.com').read()
# parse url data 1 html 2 'html.parser' 3 'utf-8'
soup = BeautifulSoup(html,'html.parser',from_encoding='utf-8')
# img
images = soup.findAll('img')
print(images)
imageName = 0 
for image in images:
    link = image.get('src')
    print('link=',link)
    link = 'http:'+link
    fileFormat = link[-3:]
    if fileFormat == 'png' or fileFormat == 'jpg':
        fileSavePath = '/Users/mac/Desktop/DL/'+str(imageName)+'.jpg'
        imageName = imageName +1 
        urllib.request.urlretrieve(link,fileSavePath)


```


== FFmpeg初识

```
# python 爬虫 # ffmpeg
# 样本采集车 -》路段-〉视频
# opencv 视频 本质-》ffmpeg
# 是什么？软件
# 文件格式 编解码 剪切 录制 提取 裁剪 复用
# 信息 ffmpeg -i 1.mp4
# 视频分解图片 ffmpeg -i 1.mp4 image%d.jpg
```


== ffmpeg

https://ffmpeg.org/

```
ffmpeg -i 1.mp4 image%d.jpg
```


== OpenCV预处理

```
# 1 load xml 2 load jpg 3 haar gray 4 detect 5 draw
import cv2
import numpy as np
# load xml 1 file name
face_xml = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
eye_xml = cv2.CascadeClassifier('haarcascade_eye.xml')
# load jpg
img = cv2.imread('face.jpg')
cv2.imshow('src',img)
# haar gray
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
# detect faces 1 data 2 scale 3 5
faces = face_xml.detectMultiScale(gray,1.3,5)
print('face=',len(faces))
# draw
index = 0
for (x,y,w,h) in faces:
    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
    roi_face = gray[y:y+h,x:x+w]
    roi_color = img[y:y+h,x:x+w]
    fileName = str(index)+'.jpg'
    cv2.imwrite(fileName,roi_color)
    index = index + 1
    # 1 gray
    eyes = eye_xml.detectMultiScale(roi_face)
    print('eye=',len(eyes))
    #for (e_x,e_y,e_w,e_h) in eyes:
        #cv2.rectangle(roi_color,(e_x,e_y),(e_x+e_w,e_y+e_h),(0,255,0),2)
cv2.imshow('dst',img)
cv2.waitKey(0)


```

== 人脸识别

```
# 1 数据yale 2 准备train label-》train 
# 3 cnn 4 检测
import tensorflow as tf
import numpy as np
import scipy.io as sio

f = open('Yale_64x64.mat','rb')
mdict = sio.loadmat(f)
# fea gnd
train_data = mdict['fea']
train_label = mdict['gnd']

train_data = np.random.permutation(train_data)
train_label = np.random.permutation(train_label)
test_data = train_data[0:64]
test_label = train_label[0:64]
np.random.seed(100)
test_data = np.random.permutation(test_data)
np.random.seed(100)
test_label = np.random.permutation(test_label)
# train [0-9] [10*N] [15*N]  [0 0 1 0 0 0 0 0 0 0] -> 2
train_data = train_data.reshape(train_data.shape[0],64,64,1).astype(np.float32)/255
train_labels_new = np.zeros((165,15))# 165 image 15
for i in range(0,165):
    j = int(train_label[i,0])-1 # 1-15 0-14 
    train_labels_new[i,j] = 1

test_data_input = test_data.reshape(test_data.shape[0],64,64,1).astype(np.float32)/255
test_labels_input = np.zeros((64,15))# 165 image 15
for i in range(0,64):
    j = int(test_label[i,0])-1 # 1-15 0-14 
    test_labels_input[i,j] = 1
# cnn acc  tf.nn tf.layer
data_input = tf.placeholder(tf.float32,[None,64,64,1])
label_input = tf.placeholder(tf.float32,[None,15])

layer1 = tf.layers.conv2d(inputs=data_input,filters=32,kernel_size=2,strides=1,padding='SAME',activation=tf.nn.relu)
layer1_pool = tf.layers.max_pooling2d(layer1,pool_size=2,strides=2)
layer2 = tf.reshape(layer1_pool,[-1,32*32*32])
layer2_relu = tf.layers.dense(layer2,1024,tf.nn.relu)
output = tf.layers.dense(layer2_relu,15)

loss = tf.losses.softmax_cross_entropy(onehot_labels=label_input,logits=output)
train = tf.train.GradientDescentOptimizer(0.01).minimize(loss)
accuracy = tf.metrics.accuracy(labels=tf.argmax(label_input,axis=1),predictions=tf.argmax(output,axis=1))[1]

# run acc
init = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
with tf.Session() as sess:
    sess.run(init)
    for i in range(0,200):
        train_data_input = np.array(train_data)
        train_label_input = np.array(train_labels_new)
        sess.run([train,loss],feed_dict={data_input:train_data_input,label_input:train_label_input})
        acc = sess.run(accuracy,feed_dict={data_input:test_data_input,label_input:test_labels_input})
        print('acc:%.2f',acc)
```

